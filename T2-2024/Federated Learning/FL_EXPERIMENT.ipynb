{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e94d7b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagrit\\AppData\\Local\\Temp/ipykernel_21396/486913775.py:13: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype={value.dtype})\n",
      "  df = pd.read_excel(file_path)\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import flwr as fl\n",
    "import pickle\n",
    "import multiprocessing as mp\n",
    "\n",
    "# Load the Excel data\n",
    "file_path = 'Customer data.xlsx'  # Ensure the file is in the correct directory or provide the full path\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d8a08b",
   "metadata": {},
   "source": [
    "**The preprocess_customer_data function prepares customer data for analysis by performing the following steps**\n",
    "\n",
    "Dropping Irrelevant Columns: It removes the 'customer_id' and 'name' columns from the DataFrame, as they are not useful for numerical analysis or modeling.\n",
    "\n",
    "Encoding Categorical Features: It encodes several categorical columns ('gender', 'job_title', 'job_industry_category', 'wealth_segment', 'deceased_indicator', and 'owns_car') into numeric format using LabelEncoder, facilitating their use in machine learning algorithms.\n",
    "\n",
    "Standardizing Numerical Features: It standardizes selected numerical columns ('past_3_years_bike_related_purchases', 'age', 'tenure') using StandardScaler, ensuring that all features contribute equally to the model.\n",
    "\n",
    "Defining Target Variable: It separates the target variable ('gender') from the feature set, returning a DataFrame of features (X) and a Series of target values (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72ddb571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the Excel data\n",
    "def preprocess_customer_data(df):\n",
    "    # Drop irrelevant columns like 'name' since they are not numeric or relevant for scaling\n",
    "    df = df.drop(columns=[\"customer_id\", \"name\"])  # Remove name and customer_id columns\n",
    "    \n",
    "    # Encode categorical columns\n",
    "    label_encoders = {}\n",
    "    categorical_cols = [\"gender\", \"job_title\", \"job_industry_category\", \"wealth_segment\", \"deceased_indicator\", \"owns_car\"]\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].astype(str))  # Convert to string before encoding\n",
    "        label_encoders[col] = le  # Store the encoder if needed for inverse transformation\n",
    "\n",
    "    # Standardize numerical features (only numeric columns)\n",
    "    scaler = StandardScaler()\n",
    "    numerical_cols = [\"past_3_years_bike_related_purchases\", \"age\", \"tenure\"]\n",
    "    df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "    # Assuming 'gender' as target for the sake of example (adjust as needed)\n",
    "    X = df.drop(columns=[\"gender\"])\n",
    "    y = df[\"gender\"]\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9bf61f",
   "metadata": {},
   "source": [
    "**The CustomerDataClient class enables federated learning on the client side by inheriting from fl.client.NumPyClient**\n",
    "\n",
    "Key Features:\n",
    "\n",
    "Initialization: Accepts a model and training/testing datasets, storing them for later use.\n",
    "\n",
    "Get Parameters: Returns the model's coefficients and intercept for use in federated updates.\n",
    "\n",
    "Fit Method: Updates the model with received parameters and trains it on local data, returning the new parameters and training sample count.\n",
    "\n",
    "Evaluate Method: Sets model parameters, evaluates performance on the test dataset, and returns accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3f5eb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class for handling federated learning on client side\n",
    "class CustomerDataClient(fl.client.NumPyClient):\n",
    "    def __init__(self, model, x_train, y_train, x_test, y_test):\n",
    "        self.model = model\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "\n",
    "    def get_parameters(self):\n",
    "        return [self.model.coef_.ravel(), self.model.intercept_]\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.model.coef_ = np.array(parameters[0]).reshape(1, -1)\n",
    "        self.model.intercept_ = np.array(parameters[1])\n",
    "        self.model.fit(self.x_train, self.y_train)\n",
    "        return [self.model.coef_.ravel(), self.model.intercept_], len(self.x_train), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.model.coef_ = np.array(parameters[0]).reshape(1, -1)\n",
    "        self.model.intercept_ = np.array(parameters[1])\n",
    "        predictions = self.model.predict(self.x_test)\n",
    "        accuracy = accuracy_score(self.y_test, predictions)\n",
    "        return 1 - accuracy, len(self.x_test), {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "831afc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Federated Learning server\n",
    "def start_fl_server(num_rounds=3):\n",
    "    strategy = fl.server.strategy.FedAvg()\n",
    "    fl.server.start_server(server_address=\"127.0.0.1:8081\", strategy=strategy, config={\"num_rounds\": num_rounds})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2e17380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Federated Learning client\n",
    "def start_fl_client(client_id):\n",
    "    with open(f'client_{client_id}_data.pkl', 'rb') as f:\n",
    "        X, y = pickle.load(f)\n",
    "\n",
    "    model = LogisticRegression()\n",
    "    split_index = int(0.8 * len(X))\n",
    "    x_train, x_test = X[:split_index], X[split_index:]\n",
    "    y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "    client = CustomerDataClient(model, x_train, y_train, x_test, y_test)\n",
    "    fl.client.start_numpy_client(server_address=\"127.0.0.1:8081\", client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "944f8bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Federated Learning experiment\n",
    "def run_federated_learning(num_clients, num_rounds=3):\n",
    "    try:\n",
    "        mp.set_start_method(\"spawn\")\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "\n",
    "    server_process = mp.Process(target=start_fl_server, args=(num_rounds,))\n",
    "    server_process.start()\n",
    "\n",
    "    client_processes = []\n",
    "    for i in range(num_clients):\n",
    "        p = mp.Process(target=start_fl_client, args=(i,))\n",
    "        client_processes.append(p)\n",
    "        p.start()\n",
    "\n",
    "    for p in client_processes:\n",
    "        p.join()\n",
    "\n",
    "    server_process.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34fc685",
   "metadata": {},
   "source": [
    "**The centralized_training_evaluation function trains and evaluates a Logistic Regression model using a centralized dataset.**\n",
    "\n",
    "**Key Steps:**\n",
    "\n",
    "Numeric Data Selection: Filters the input feature set (X) to retain only numeric columns.\n",
    "\n",
    "Data Cleaning: Creates a mask to remove rows with missing values in either X or the target variable (y), ensuring alignment between features and labels.\n",
    "\n",
    "Data Scaling: Standardizes the cleaned feature set using StandardScaler.\n",
    "\n",
    "Model Training: Trains a Logistic Regression model on the scaled data.\n",
    "\n",
    "Prediction and Evaluation: Makes predictions on the training data and calculates the accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f9fbac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def centralized_training_evaluation(X, y):\n",
    "    # Ensure we are working only with numeric data for this function\n",
    "    X_numeric = X.select_dtypes(include=[np.number])\n",
    "    \n",
    "    # Make sure both X and y don't have mismatched rows\n",
    "    mask = ~np.isnan(y) & ~np.isnan(X_numeric).any(axis=1)\n",
    "    \n",
    "    # Filter X and y based on the mask\n",
    "    X_cleaned = X_numeric[mask]\n",
    "    y_cleaned = y[mask]\n",
    "\n",
    "    # Train a Logistic Regression model on the entire dataset\n",
    "    scaler = StandardScaler()\n",
    "    X_cleaned_scaled = scaler.fit_transform(X_cleaned)\n",
    "    \n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_cleaned_scaled, y_cleaned)\n",
    "    \n",
    "    # Predict and evaluate using accuracy score\n",
    "    predictions = model.predict(X_cleaned_scaled)\n",
    "    centralized_accuracy = accuracy_score(y_cleaned, predictions)\n",
    "    \n",
    "    return centralized_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2f4e15",
   "metadata": {},
   "source": [
    "**The simulate_federated_learning function simulates a federated learning scenario with three clients.**\n",
    "\n",
    "**Key Steps:**\n",
    "\n",
    "Client Data Preparation: Splits the dataset into three subsets for each client, saving the data to files.\n",
    "\n",
    "Federated Learning: Initiates federated learning by calling run_federated_learning for a specified number of rounds.\n",
    "\n",
    "Model Evaluation: Evaluates the federated model on the last client's data after cleaning it to ensure only numeric values and handling NaN/infinite values.\n",
    "\n",
    "Training and Prediction: Trains a Logistic Regression model on the second-to-last client's data and predicts on the last client's test data.\n",
    "\n",
    "Accuracy Calculation: Computes and prints the accuracy for both the federated and centralized models for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be8a1fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_federated_learning():\n",
    "    num_clients = 3  # Set the number of clients\n",
    "    client_data = []\n",
    "\n",
    "    # Split data into multiple clients\n",
    "    for i in range(num_clients):\n",
    "        X_split = X.sample(frac=1/num_clients, random_state=i)\n",
    "        y_split = y.loc[X_split.index]\n",
    "        client_data.append((X_split, y_split))\n",
    "        with open(f'client_{i}_data.pkl', 'wb') as f:\n",
    "            pickle.dump((X_split, y_split), f)\n",
    "\n",
    "    print(\"\\nStarting Federated Learning...\")\n",
    "    run_federated_learning(num_clients - 1, num_rounds=3)\n",
    "\n",
    "    print(\"\\nEvaluating Federated Model on the remaining client dataset...\")\n",
    "    X_test, y_test = client_data[-1]\n",
    "    \n",
    "    # Ensure only numeric columns are scaled and NaN/infinite values are handled\n",
    "    X_test = X_test.select_dtypes(include=[np.number])  # Only select numeric columns\n",
    "    X_test = np.nan_to_num(X_test, nan=0.0, posinf=1e10, neginf=-1e10)  # Replace NaN, inf values\n",
    "\n",
    "    with open(f'client_{num_clients - 2}_data.pkl', 'rb') as f:\n",
    "        X_last_client, y_last_client = pickle.load(f)\n",
    "\n",
    "    # Apply same cleaning for last client data\n",
    "    X_last_client = X_last_client.select_dtypes(include=[np.number])  # Ensure only numeric data\n",
    "    X_last_client = np.nan_to_num(X_last_client, nan=0.0, posinf=1e10, neginf=-1e10)  # Replace NaN, inf values\n",
    "    y_last_client = np.nan_to_num(y_last_client, nan=0.0, posinf=1e10, neginf=-1e10)  # Same for labels\n",
    "    \n",
    "    # Train and evaluate the model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_last_client, y_last_client)\n",
    "    \n",
    "    # Predict on test data\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Calculate federated accuracy\n",
    "    federated_accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "    print(\"\\nRunning Centralized Model for comparison...\")\n",
    "    centralized_accuracy = centralized_training_evaluation(X, y)\n",
    "\n",
    "    print(f\"\\nFederated model accuracy: {federated_accuracy:.4f}\")\n",
    "    print(f\"Centralized model accuracy: {centralized_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be79368a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Federated Learning...\n",
      "\n",
      "Evaluating Federated Model on the remaining client dataset...\n",
      "\n",
      "Running Centralized Model for comparison...\n",
      "\n",
      "Federated model accuracy: 0.5116\n",
      "Centralized model accuracy: 0.5263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagrit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Start the simulation\n",
    "simulate_federated_learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b54da40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
